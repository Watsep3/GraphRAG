import streamlit as st
import sys
import os
import json
import plotly.graph_objects as go
import networkx as nx
from datetime import datetime
import pandas as pd

# Ajouter le chemin src
sys.path.append('C:/Projects/GraphRAG/src')

# from rag.rag_pipeline import GraphRAGPipeline
from rag.rag_pipeline_ollama import GraphRAGPipeline
from neo4j import GraphDatabase
import pickle

# Configuration de la page
st.set_page_config(
    page_title="GraphRAG Demo",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
    }
    .entity-card {
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #ddd;
        margin: 0.5rem 0;
        background-color: #f8f9fa;
    }
    .metric-container {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_pipeline():
    """Charge le pipeline (cached pour √©viter de recharger)"""
    with st.spinner("üîÑ Chargement du mod√®le GraphRAG..."):
        try:
            # Essayer le fichier enrichi d'abord
            embeddings_path = 'C:/Projects/GraphRAG/models/embeddings/entity_embeddings_named.pkl'
            
            # Fallback vers fichier original si pas trouv√©
            if not os.path.exists(embeddings_path):
                embeddings_path = 'C:/Projects/GraphRAG/models/embeddings/entity_embeddings.pkl'
                st.warning("‚ö†Ô∏è Utilisation des embeddings sans noms enrichis")
            
            pipeline = GraphRAGPipeline(
                embeddings_path=embeddings_path,
                ollama_model='llama3.2:3b'
            )
            return pipeline, None
        except Exception as e:
            return None, str(e)

@st.cache_data
def load_entity_names():
    """Charge le mapping des noms d'entit√©s"""
    try:
        with open('C:/Projects/GraphRAG/models/embeddings/entity_embeddings_named.pkl', 'rb') as f:
            data = pickle.load(f)
            entity_names = data.get('entity_names', {})
            return entity_names
    except FileNotFoundError:
        return {}
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erreur chargement noms: {e}")
        return {}

def visualize_graph(entities: list, relations: list = None):
    """Cr√©e une visualisation du sous-graphe"""
    
    # Cr√©er un graphe NetworkX
    G = nx.Graph()
    
    # Ajouter les n≈ìuds
    for entity in entities:
        G.add_node(entity)
    
    # Ajouter les ar√™tes si disponibles
    if relations:
        for rel in relations:
            if 'source' in rel and 'target' in rel:
                G.add_edge(rel['source'], rel['target'], label=rel.get('type', ''))
    
    # Calculer les positions
    pos = nx.spring_layout(G, k=0.5, iterations=50)
    
    # Cr√©er les traces Plotly
    edge_trace = go.Scatter(
        x=[], y=[],
        line=dict(width=0.5, color='#888'),
        hoverinfo='none',
        mode='lines'
    )
    
    # Ajouter les ar√™tes
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_trace['x'] += tuple([x0, x1, None])
        edge_trace['y'] += tuple([y0, y1, None])
    
    # N≈ìuds
    node_trace = go.Scatter(
        x=[],
        y=[],
        text=[],
        mode='markers+text',
        hoverinfo='text',
        marker=dict(
            size=20,
            color='#1f77b4',
            line_width=2
        ),
        textposition="top center"
    )
    
    for node in G.nodes():
        x, y = pos[node]
        node_trace['x'] += tuple([x])
        node_trace['y'] += tuple([y])
        node_trace['text'] += tuple([node[:20]])  # Limiter la longueur
    
    # Cr√©er la figure
    fig = go.Figure(
        data=[edge_trace, node_trace],
        layout=go.Layout(
            showlegend=False,
            hovermode='closest',
            margin=dict(b=0, l=0, r=0, t=0),
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=400
        )
    )
    
    return fig

def display_entity_details(entity: str, pipeline: GraphRAGPipeline):
    """Affiche les d√©tails d'une entit√©"""
    
    with st.expander(f"üîç D√©tails: {entity}", expanded=False):
        try:
            context = pipeline.retriever.get_entity_context(entity)
            
            if context['relations']:
                st.write("**Relations:**")
                for rel in context['relations'][:10]:
                    st.markdown(f"- `{rel['relation']}` ‚Üí **{rel['target']}**")
            else:
                st.info("Aucune relation trouv√©e dans le graphe")
                
        except Exception as e:
            st.error(f"Erreur: {e}")

def main():
    # Header
    st.markdown('<p class="main-header">üß† GraphRAG Demo</p>', unsafe_allow_html=True)
    st.markdown("**Repr√©sentation Conjointe de Texte et Graphes** | Recherche Hybride Intelligente")
    
    # Sidebar
    with st.sidebar:
        st.image("https://via.placeholder.com/300x100/1f77b4/ffffff?text=GraphRAG", use_container_width=True)
        
        st.markdown("---")
        st.markdown("## ‚öôÔ∏è Configuration")
        
        k_text = st.slider("Top-K R√©sultats Texte", 1, 20, 5)
        k_graph = st.slider("Top-K Contexte Graphe", 1, 30, 10)
        max_hops = st.slider("Profondeur Graphe (sauts)", 1, 3, 2)
        
        st.markdown("---")
        st.markdown("## üìä Statistiques")
        
        # Charger les stats
        try:
            with open('C:/Projects/GraphRAG/models/embeddings/entity_embeddings.pkl', 'rb') as f:
                data = pickle.load(f)
                n_entities = len(data['entities']) if isinstance(data, dict) else len(data)
            
            st.metric("Entit√©s Index√©es", f"{n_entities:,}")
        except:
            st.metric("Entit√©s Index√©es", "N/A")
        
        st.markdown("---")
        st.markdown("## üîå Statut des Services")
        
        # Placeholder pour les statuts (sera rempli apr√®s chargement du pipeline)
        status_container = st.empty()
        
        st.markdown("---")
        st.markdown("## üìñ √Ä Propos")
        st.info("""
        Ce syst√®me combine:
        - üî§ Encodage textuel (Sentence-BERT)
        - üï∏Ô∏è Encodage graphe (GNN)
        - üîó Alignement cross-modal
        - üéØ RAG hybride
        - ü¶ô G√©n√©ration Ollama
        """)

    # Charger le pipeline
    pipeline, error = load_pipeline()

    if error:
        st.error(f"‚ùå Erreur de chargement: {error}")
        st.stop()

    st.success("‚úÖ Mod√®le charg√© avec succ√®s!")

    # Maintenant qu'on a le pipeline, on peut afficher les statuts
    with status_container.container():
        col1, col2 = st.columns(2)
        
        neo4j_status = pipeline.retriever.neo4j_available
        ollama_status = pipeline.generator.ollama_available
        
        col1.metric("Neo4j", "‚úÖ Actif" if neo4j_status else "‚ùå Inactif")
        col2.metric("Ollama", "‚úÖ Actif" if ollama_status else "‚ùå Inactif")
    
    # Tabs principales
    tab1, tab2, tab3, tab4 = st.tabs(["üîç Recherche", "üìä Analyse", "üß™ Benchmark", "üìö Documentation"])
    
    # TAB 1: RECHERCHE
    with tab1:
        st.markdown("## üîç Recherche Hybride Texte-Graphe")
        
        # Zone de requ√™te
        col1, col2 = st.columns([4, 1])
        
        with col1:
            query = st.text_input(
                "Posez votre question:",
                placeholder="Ex: What is machine learning? Who is Barack Obama?",
                key="query_input"
            )
        
        with col2:
            search_button = st.button("üîé Rechercher", type="primary")
        
        # Exemples de questions
        st.markdown("**Exemples:**")
        example_cols = st.columns(3)
        
        examples = [
            "What is artificial intelligence?",
            "Tell me about neural networks",
            "Who invented the computer?"
        ]
        
        for i, (col, example) in enumerate(zip(example_cols, examples)):
            if col.button(example, key=f"example_{i}"):
                query = example
                search_button = True
        
        # Ex√©cuter la recherche
        if search_button and query:
            with st.spinner("üîÑ Recherche en cours..."):
                try:
                    # Effectuer la recherche
                    result = pipeline.query(query, k_text=k_text, k_graph=k_graph)
                    
                    # Stocker dans session_state
                    st.session_state['last_result'] = result
                    st.session_state['last_query'] = query
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur: {e}")
                    st.stop()
        
        # Afficher les r√©sultats
        if 'last_result' in st.session_state:
            result = st.session_state['last_result']
            
            st.markdown("---")
            st.markdown("### üìù R√©sultats")
            
            # M√©triques rapides
            metric_cols = st.columns(3)
            metric_cols[0].metric("üìö Entit√©s Texte", len(result.get('text_results', [])))
            metric_cols[1].metric("üï∏Ô∏è Entit√©s Graphe", len(result.get('graph_context', [])))
            metric_cols[2].metric("üéØ Total Unique", len(result.get('entities', [])))

            # Ajouter un indicateur si Neo4j n'est pas utilis√©
            if not result.get('neo4j_used', False):
                st.warning("‚ö†Ô∏è Neo4j non utilis√© - R√©sultats bas√©s uniquement sur la recherche textuelle")

            # R√©sultats textuels
            st.markdown("#### üî§ Top R√©sultats (Recherche Textuelle)")
            
            # Charger les noms d'entit√©s
            entity_names = load_entity_names()
            
            for i, text_res in enumerate(result.get('text_results', [])[:k_text], 1):
                entity_id = text_res['entity']
                entity_name = entity_names.get(entity_id, entity_id)
                
                with st.container():
                    col1, col2, col3, col4 = st.columns([0.5, 3.5, 2.5, 1])
                    
                    col1.markdown(f"**#{i}**")
                    
                    # Afficher le nom avec style selon disponibilit√©
                    if entity_name.startswith('['):
                        # ID nettoy√© (pas trouv√© dans Wikidata)
                        col2.markdown(f"*{entity_name}*")
                    else:
                        # Vrai nom trouv√©
                        col2.markdown(f"**{entity_name}**")
                    
                    # Afficher l'ID Freebase
                    col3.markdown(f"`{entity_id}`")
                    
                    # Score
                    col4.markdown(f"`{text_res['score']:.3f}`")
                    
                    # Bouton pour d√©tails
                    if st.button(f"Voir d√©tails", key=f"detail_text_{i}"):
                        display_entity_details(entity_id, pipeline)
            
            st.markdown("---")
            
            # Contexte graphe
            st.markdown("#### üï∏Ô∏è Contexte du Graphe (Entit√©s Connect√©es)")

            graph_entities = result.get('graph_context', [])[:k_graph]

            if graph_entities:
                # Enrichir avec les noms
                for entity_dict in graph_entities:
                    entity_id = entity_dict['entity']
                    entity_dict['name'] = entity_names.get(entity_id, entity_id)
                
                # Tableau avec noms
                df_graph = pd.DataFrame(graph_entities)
                
                # S√©lectionner les colonnes √† afficher
                display_cols = ['name', 'entity', 'hops'] if 'name' in df_graph.columns else ['entity', 'hops']
                
                st.dataframe(
                    df_graph[display_cols].head(10),
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "name": st.column_config.TextColumn("Nom", width="large"),
                        "entity": st.column_config.TextColumn("ID Freebase", width="medium"),
                        "hops": st.column_config.NumberColumn("Distance", width="small")
                    }
                )
                
                # Visualisation du graphe
                st.markdown("#### üìä Visualisation du Sous-Graphe")
                
                try:
                    all_entities = [r['entity'] for r in result.get('text_results', [])[:3]]
                    all_entities += [g['entity'] for g in graph_entities[:7]]
                    
                    fig = visualize_graph(list(set(all_entities)))
                    st.plotly_chart(fig, use_container_width=True)
                    
                except Exception as e:
                    st.warning(f"Visualisation non disponible: {e}")
            
            else:
                st.info("Aucun contexte graphe disponible")
            
            st.markdown("---")
            
            # R√©ponse compl√®te
            with st.expander("üìÑ Voir la R√©ponse Compl√®te", expanded=False):
                st.code(result.get('answer', 'N/A'), language='text')
    
    # TAB 2: ANALYSE
    with tab2:
        st.markdown("## üìä Analyse des Embeddings")
        
        st.markdown("""
        Cette visualisation utilise **t-SNE** (t-Distributed Stochastic Neighbor Embedding) 
        pour projeter les embeddings 384D dans un espace 2D, r√©v√©lant la structure s√©mantique.
        """)
        
        # Configuration t-SNE
        col1, col2, col3 = st.columns(3)
        
        with col1:
            sample_size = st.slider("√âchantillon", 500, 5000, 2000, 500)
        with col2:
            perplexity = st.slider("Perplexity", 5, 50, 30, 5)
        with col3:
            n_clusters = st.slider("Nombre de Clusters", 3, 15, 8, 1)
        
        # Bouton de g√©n√©ration
        if st.button("üé® G√©n√©rer Visualisation t-SNE", type="primary"):
            with st.spinner("‚è≥ Calcul en cours (cela peut prendre 1-2 minutes)..."):
                try:
                    from visualize_tsne import EmbeddingVisualizer
                    
                    # Cr√©er visualiseur
                    viz = EmbeddingVisualizer(
                        'C:/Projects/GraphRAG/models/embeddings/entity_embeddings.pkl'
                    )
                    
                    # Calculer t-SNE
                    progress_bar = st.progress(0)
                    st.info("√âtape 1/3: Calcul t-SNE...")
                    
                    viz.compute_tsne(
                        n_components=2,
                        perplexity=perplexity,
                        max_iter=1000,
                        sample_size=sample_size
                    )
                    progress_bar.progress(33)
                    
                    # Cr√©er visualisation
                    st.info("√âtape 2/3: G√©n√©ration du graphique...")
                    fig = viz.create_interactive_plot(
                        title=f"t-SNE: Entity Embeddings (n={sample_size})"
                    )
                    progress_bar.progress(66)
                    
                    # D√©tecter clusters
                    st.info("√âtape 3/3: D√©tection des clusters...")
                    clusters = viz.find_clusters(n_clusters=n_clusters)
                    fig_clusters = viz.plot_clusters()
                    progress_bar.progress(100)
                    
                    # Sauvegarder dans session state
                    st.session_state['tsne_fig'] = fig
                    st.session_state['tsne_fig_clusters'] = fig_clusters
                    st.session_state['clusters_info'] = clusters
                    
                    st.success("‚úÖ Visualisation g√©n√©r√©e!")
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur: {e}")
                    import traceback
                    st.code(traceback.format_exc())
        
        # Afficher les visualisations si disponibles
        if 'tsne_fig' in st.session_state:
            st.markdown("---")
            
            # Tabs pour les deux visualisations
            viz_tab1, viz_tab2, viz_tab3 = st.tabs(["üìä t-SNE Standard", "üéØ t-SNE avec Clusters", "üìã Analyse des Clusters"])
            
            with viz_tab1:
                st.markdown("### Projection t-SNE des Embeddings")
                st.plotly_chart(st.session_state['tsne_fig'], use_container_width=True)
                
                st.info("""
                **Interpr√©tation:**
                - Les entit√©s proches dans l'espace t-SNE ont des embeddings similaires
                - Les clusters visibles indiquent des groupes s√©mantiques
                - Vous pouvez zoomer et survoler les points pour voir les entit√©s
                """)
            
            with viz_tab2:
                st.markdown("### t-SNE avec Clustering K-Means")
                st.plotly_chart(st.session_state['tsne_fig_clusters'], use_container_width=True)
                
                st.info("""
                **Clusters color√©s:**
                - Chaque couleur repr√©sente un cluster d√©couvert automatiquement
                - Les clusters peuvent correspondre √† des cat√©gories s√©mantiques
                """)
            
            with viz_tab3:
                st.markdown("### Analyse des Clusters")
                
                if 'clusters_info' in st.session_state:
                    clusters = st.session_state['clusters_info']
                    
                    # Statistiques globales
                    st.markdown("### üìä Statistiques Globales")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    total_entities = sum(info['size'] for info in clusters.values())
                    avg_cluster_size = total_entities / len(clusters)
                    sizes = [info['size'] for info in clusters.values()]
                    largest_size = max(sizes)
                    
                    col1.metric("Total Entit√©s", total_entities)
                    col2.metric("Taille Moyenne", f"{avg_cluster_size:.0f}")
                    col3.metric("Plus Grand Cluster", largest_size)
                    
                    st.markdown("---")
                    
                    # Afficher les clusters
                    for cluster_name, info in clusters.items():
                        with st.expander(f"{cluster_name} - {info['size']} entit√©s"):
                            st.markdown(f"**Taille:** {info['size']} entit√©s")
                            st.markdown("**Entit√©s repr√©sentatives:**")
                            for entity in info['entities'][:10]:
                                st.markdown(f"- `{entity}`")
        
        else:
            st.info("üëÜ Cliquez sur le bouton ci-dessus pour g√©n√©rer la visualisation t-SNE")
    
    # TAB 3: BENCHMARK
    with tab3:
        st.markdown("## üß™ R√©sultats de Benchmark")
        
        # Charger les r√©sultats d'√©valuation
        results_file = 'C:/Projects/GraphRAG/results/evaluation_results.json'
        
        if os.path.exists(results_file):
            with open(results_file, 'r') as f:
                metrics = json.load(f)
            
            st.markdown("### üìà M√©triques de Performance")
            
            # Afficher les m√©triques
            cols = st.columns(2)
            
            for i, (metric, value) in enumerate(metrics.items()):
                col = cols[i % 2]
                col.metric(metric.upper(), f"{value:.4f}")
            
            # Graphique
            fig = go.Figure(data=[
                go.Bar(
                    x=list(metrics.keys()),
                    y=list(metrics.values()),
                    marker_color='#1f77b4'
                )
            ])
            
            fig.update_layout(
                title="M√©triques d'√âvaluation",
                xaxis_title="M√©trique",
                yaxis_title="Score",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        else:
            st.warning("‚ö†Ô∏è Aucun r√©sultat de benchmark disponible")
            st.info("Ex√©cutez `python src/evaluation.py` pour g√©n√©rer les m√©triques")
    
    # TAB 4: DOCUMENTATION
    with tab4:
        st.markdown("## üìö Documentation")
        
        st.markdown("""
        ### üéØ Objectif du Projet
        
        Ce syst√®me impl√©mente une approche de **Repr√©sentation Conjointe de Texte et Graphes**
        pour am√©liorer la recherche d'information et la g√©n√©ration de r√©ponses.
        
        ### üèóÔ∏è Architecture
        
        #### 1. Encodage Textuel
        - **Mod√®le**: Sentence-BERT (all-MiniLM-L6-v2)
        - **Dimension**: 384
        - **Fonction**: Encode les noms d'entit√©s et questions en vecteurs
        
        #### 2. Encodage Graphe
        - **Mod√®le**: GraphSAGE (GNN)
        - **Dimension**: 384
        - **Fonction**: Capture la structure du graphe de connaissances
        
        #### 3. Alignement Cross-Modal
        - **Architecture**: Projection Network
        - **Loss**: Contrastive Loss (bidirectionnel)
        - **Objectif**: Aligner les espaces texte et graphe
        
        #### 4. RAG Pipeline
        - **Retriever**: FAISS + Neo4j
        - **Generator**: Ollama LLM (llama3.2:3b)
        - **Strat√©gie**: Recherche hybride texte-graphe
        
        ### üìä Datasets Utilis√©s
        
        - **FB15k-237**: Graphe de connaissances (14,505 entit√©s, 237 relations)
        - **HotpotQA**: Questions multi-hop
        - **Wikidata**: Enrichissement des noms d'entit√©s
        
        ### üöÄ Utilisation
```python
from rag.rag_pipeline_ollama import GraphRAGPipeline

# Initialiser
pipeline = GraphRAGPipeline(
    embeddings_path='path/to/embeddings.pkl',
    ollama_model='llama3.2:3b'
)

# Requ√™te
result = pipeline.query("What is AI?", k_text=5, k_graph=10)
print(result['answer'])
```
        
        ### üìà Performances
        
        - **Recall@5**: 60.0%
        - **MRR**: 80.9%
        - **Precision@5**: 20.8%
        - **F1@5**: 30.5%
        - **Temps de recherche**: <100ms
        
        ### üîß Technologies
        
        - PyTorch 2.5.1 + PyTorch Geometric
        - Sentence-Transformers (all-MiniLM-L6-v2)
        - Neo4j 5.x (272K+ relations)
        - FAISS (14K+ embeddings)
        - Ollama (llama3.2:3b local)
        - Streamlit
        
        ### üë®‚Äçüíª Auteurs
        
        **Salma Berrada & Marwa Ghachi**
        
        Universit√© Internationale de Rabat (UIR)
        
        Projet de Fin d'√âtudes - Big Data & IA - Semestre 9 (2025-2026)
        
        Superviseur: Prof. Hakim Hafidi
        """)
    
    # Footer
    st.markdown("---")
    st.markdown(
        f"<div style='text-align: center; color: gray;'>"
        f"GraphRAG Demo v1.0 | ¬© 2025 UIR | "
        f"Derni√®re mise √† jour: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        f"</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()